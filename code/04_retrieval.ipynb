{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Vectorstore Retrieval\n",
                "\n",
                "Grasp advanced techniques for accessing and indexing data in the vector store, enabling you to retrieve the most relevant information beyond semantic queries.\n",
                "\n",
                "# Setup\n",
                "\n",
                "## Python {.smaller}\n"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
                "from langchain.document_loaders import PyPDFLoader\n",
                "from langchain.retrievers import TFIDFRetriever\n",
                "from langchain.retrievers import SVMRetriever\n",
                "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
                "from langchain.retrievers import ContextualCompressionRetriever\n",
                "from langchain.chains.query_constructor.base import AttributeInfo\n",
                "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
                "from langchain.llms import OpenAI\n",
                "from langchain.embeddings.openai import OpenAIEmbeddings\n",
                "from langchain.vectorstores import Chroma\n",
                "from dotenv import load_dotenv, find_dotenv\n",
                "import os\n",
                "import openai\n",
                "# import sys\n",
                "# sys.path.append('../..')\n",
                "\n",
                "_ = load_dotenv(find_dotenv())  # read local .env file\n",
                "\n",
                "openai.api_key = os.environ['OPENAI_API_KEY']"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Vector Database\n",
                "\n",
                "## Setup\n",
                "\n",
                "Let's get our vectorDB from Tutorial 3."
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "persist_directory = '../docs/chroma/'"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                ""
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "embedding = OpenAIEmbeddings()"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                ""
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "vectordb = Chroma(\n",
                "    persist_directory=persist_directory,\n",
                "    embedding_function=embedding\n",
                ")"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                ""
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "print(vectordb._collection.count())"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- 209\n",
                "\n",
                "## Example"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "texts = [\n",
                "    \"\"\"The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).\"\"\",\n",
                "    \"\"\"A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.\"\"\",\n",
                "    \"\"\"A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.\"\"\",\n",
                "]"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                ""
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "smalldb = Chroma.from_texts(texts, embedding=embedding)"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                ""
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "question = \"Tell me about all-white mushrooms with large fruiting bodies\""
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Result 1"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "smalldb.similarity_search(question, k=2)"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- [Document(page_content='A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.', metadata={}),\n",
                " Document(page_content='The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).', metadata={})]\n",
                "\n",
                "\n",
                "## Result 2"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "smalldb.max_marginal_relevance_search(question, k=2, fetch_k=3)"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- [Document(page_content='A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.', metadata={}),\n",
                " Document(page_content='A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.', metadata={})]\n",
                "\n",
                "# Addressing Diversity\n",
                "\n",
                "## Basics\n",
                "\n",
                "- Addressing Diversity: Maximum marginal relevance (MMR)\n",
                "\n",
                "- In Tutorial 3 we introduced one problem: how to enforce diversity in the search results.\n",
                " \n",
                "- `Maximum marginal relevance` strives to achieve both relevance to the query *and diversity* among the results.\n",
                "\n",
                "## Question about matlab"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "question = \"what did they say about matlab?\""
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Similarity search\n",
                "\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "docs_ss = vectordb.similarity_search(question, k=3)"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Results"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "docs_ss[0].page_content[:100]"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- 'those homeworks will be done in either MATLA B or in Octave, which is sort of — I \\nknow some people '\n",
                "\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "docs_ss[1].page_content[:100]"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- 'those homeworks will be done in either MATLA B or in Octave, which is sort of — I \\nknow some people '\n",
                "\n",
                "## MMR {.smaller}\n"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "docs_mmr = vectordb.max_marginal_relevance_search(question, k=3)"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Note the difference in results with `MMR`.\n",
                "\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "docs_mmr[0].page_content[:100]"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- 'those homeworks will be done in either MATLA B or in Octave, which is sort of — I \\nknow some people '\n",
                "\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "docs_mmr[1].page_content[:100]"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- \"mathematical work, he feels like he's disc overing truth and beauty in the universe. And \\nhe says it\"\n",
                "\n",
                "# Addressing Specificity: Metadata\n",
                "\n",
                "## Basics\n",
                "\n",
                "- Addressing Specificity: working with metadata\n",
                "\n",
                "- In Tutorial 3, we showed that a question about the third lecture can include results from other lectures as well.\n",
                "\n",
                "- To address this, many vectorstores support operations on `metadata`.\n",
                "\n",
                "- `metadata` provides context for each embedded chunk.\n",
                "\n",
                "## Question about third lecture"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "question = \"what did they say about regression in the third lecture?\""
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Similarity search\n",
                "\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "docs = vectordb.similarity_search(\n",
                "    question,\n",
                "    k=3,\n",
                "    filter={\"source\": \"../docs/cs229_lectures/MachineLearning-Lecture03.pdf\"}\n",
                ")"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Result\n"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "for d in docs:\n",
                "    print(d.metadata)"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- {'source': '../docs/cs229_lectures/MachineLearning-Lecture03.pdf', 'page': 0}\n",
                "- {'source': '../docs/cs229_lectures/MachineLearning-Lecture03.pdf', 'page': 14}\n",
                "- {'source': '../docs/cs229_lectures/MachineLearning-Lecture03.pdf', 'page': 4}\n",
                "\n",
                "# Addressing Specificity: Self-query retriever\n",
                "\n",
                "## Basics {.smaller}\n",
                "\n",
                "- Addressing Specificity: working with metadata using self-query retriever\n",
                "\n",
                "- But we have an interesting challenge: we often want to infer the metadata from the query itself.\n",
                "\n",
                "- To address this, we can use `SelfQueryRetriever`, which uses an LLM to extract:\n",
                " \n",
                "1. The `query` string to use for vector search\n",
                "2. A metadata filter to pass in as well\n",
                "\n",
                "- Most vector databases support metadata filters, so this doesn't require any new databases or indexes.\n",
                "\n",
                "## metadata_field_info"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "metadata_field_info = [\n",
                "    AttributeInfo(\n",
                "        name=\"source\",\n",
                "        description=\"The lecture the chunk is from, should be one of `../docs/cs229_lectures/MachineLearning-Lecture01.pdf`, `../docs/cs229_lectures/MachineLearning-Lecture02.pdf`, or `../docs/cs229_lectures/MachineLearning-Lecture03.pdf`\",\n",
                "        type=\"string\",\n",
                "    ),\n",
                "    AttributeInfo(\n",
                "        name=\"page\",\n",
                "        description=\"The page from the lecture\",\n",
                "        type=\"integer\",\n",
                "    ),\n",
                "]"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## document_content_description"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "document_content_description = \"Lecture notes\"\n",
                "llm = OpenAI(temperature=0)\n",
                "retriever = SelfQueryRetriever.from_llm(\n",
                "    llm,\n",
                "    vectordb,\n",
                "    document_content_description,\n",
                "    metadata_field_info,\n",
                "    verbose=True\n",
                ")"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Question about third lecture"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "question = \"what did they say about regression in the third lecture?\""
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Retriever\n",
                "\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "docs = retriever.get_relevant_documents(question)"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- *You will receive a warning* about predict_and_parse being deprecated the first time you executing the next line. This can be safely ignored.\n",
                "\n",
                "## Result"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "for doc in docs:\n",
                "    print(doc.metadata)"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "```markdown\n",
                "{'source': '../docs/cs229_lectures/MachineLearning-Lecture03.pdf', 'page': 14}\n",
                "{'source': '../docs/cs229_lectures/MachineLearning-Lecture03.pdf', 'page': 0}\n",
                "{'source': '../docs/cs229_lectures/MachineLearning-Lecture03.pdf', 'page': 10}\n",
                "{'source': '../docs/cs229_lectures/MachineLearning-Lecture03.pdf', 'page': 10}\n",
                "```\n",
                "\n",
                "# Additional Tricks: Compression\n",
                "\n",
                "## Basics {.smaller}\n",
                "\n",
                "- Another approach for improving the quality of retrieved docs is compression.\n",
                "\n",
                "- Information most relevant to a query may be buried in a document with a lot of irrelevant text. \n",
                "\n",
                "- Passing that full document through your application can lead to more expensive LLM calls and poorer responses.\n",
                "\n",
                "- Contextual compression is meant to fix this. \n",
                "\n",
                "## Helper function: pretty print"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "def pretty_print_docs(docs):\n",
                "    print(f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\\n\" +\n",
                "          d.page_content for i, d in enumerate(docs)]))\n"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Load LLM"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "# Wrap our vectorstore\n",
                "llm = OpenAI(temperature=0)\n",
                "compressor = LLMChainExtractor.from_llm(llm)"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ContextualCompressionRetriever"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "compression_retriever = ContextualCompressionRetriever(\n",
                "    base_compressor=compressor,\n",
                "    base_retriever=vectordb.as_retriever()\n",
                ")"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Question about matlab"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "question = \"what did they say about matlab?\""
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Retriever\n",
                "\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "compressed_docs = compression_retriever.get_relevant_documents(question)"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Result {.smaller}"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "pretty_print_docs(compressed_docs)"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "```markdown\n",
                "Document 1:\n",
                "\n",
                "\"MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to plot data. And it's sort of an extremely easy to learn tool to use for implementing a lot of learning algorithms.\"\n",
                "----------------------------------------------------------------------------------------------------\n",
                "Document 2:\n",
                "\n",
                "\"MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to plot data. And it's sort of an extremely easy to learn tool to use for implementing a lot of learning algorithms.\"\n",
                "----------------------------------------------------------------------------------------------------\n",
                "Document 3:\n",
                "\n",
                "\"And the student said, \"Oh, it was the MATLAB.\" So for those of you that don't know MATLAB yet, I hope you do learn it. It's not hard, and we'll actually have a short MATLAB tutorial in one of the discussion sections for those of you that don't know it.\"\n",
                "----------------------------------------------------------------------------------------------------\n",
                "Document 4:\n",
                "\n",
                "\"And the student said, \"Oh, it was the MATLAB.\" So for those of you that don't know MATLAB yet, I hope you do learn it. It's not hard, and we'll actually have a short MATLAB tutorial in one of the discussion sections for those of you that don't know it.\"\n",
                "```\n",
                "\n",
                "# Combining Various Techniques\n",
                "\n",
                "## ContextualCompressionRetriever with MMR"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "compression_retriever = ContextualCompressionRetriever(\n",
                "    base_compressor=compressor,\n",
                "    base_retriever=vectordb.as_retriever(search_type=\"mmr\")\n",
                ")"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Question"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "question = \"what did they say about matlab?\""
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                " - Retriever\n",
                "\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "compressed_docs = compression_retriever.get_relevant_documents(question)"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Result"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "pretty_print_docs(compressed_docs)"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "```markdown\n",
                "\n",
                "Document 1:\n",
                "\n",
                "\"MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to plot data. And it's sort of an extremely easy to learn tool to use for implementing a lot of learning algorithms.\"\n",
                "----------------------------------------------------------------------------------------------------\n",
                "Document 2:\n",
                "\n",
                "\"And the student said, \"Oh, it was the MATLAB.\" So for those of you that don't know MATLAB yet, I hope you do learn it. It's not hard, and we'll actually have a short MATLAB tutorial in one of the discussion sections for those of you that don't know it.\"\n",
                "```\n",
                "\n",
                "# Other Types of Retrieval\n",
                "\n",
                "## Basics\n",
                "\n",
                "- It's worth noting that vectordb as not the only kind of tool to retrieve documents. \n",
                "\n",
                "- The `LangChain` retriever abstraction includes other ways to retrieve documents, such as TF-IDF or SVM.\n",
                "\n",
                "\n",
                "## Load "
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "# Load PDF\n",
                "loader = PyPDFLoader(\"../docs/cs229_lectures/MachineLearning-Lecture01.pdf\")\n",
                "\n",
                "pages = loader.load()\n",
                "\n",
                "all_page_text = [p.page_content for p in pages]\n",
                "\n",
                "joined_page_text = \" \".join(all_page_text)"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Split "
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "# Split\n",
                "text_splitter = RecursiveCharacterTextSplitter(\n",
                "    chunk_size=1500, chunk_overlap=150)\n",
                "\n",
                "splits = text_splitter.split_text(joined_page_text)"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Retrieve with SVM and TF-IDF\n",
                "\n",
                "- [Support vector machine (SVMs) retriever](https://python.langchain.com/docs/integrations/retrievers/svm)\n",
                "\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "# Retrieve\n",
                "svm_retriever = SVMRetriever.from_texts(splits, embedding)"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- [TF-IDF: term-frequency times inverse document-frequency retriever](https://python.langchain.com/docs/integrations/retrievers/tf_idf)\n",
                "\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "tfidf_retriever = TFIDFRetriever.from_texts(splits)"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## SVM retriever {.smaller}"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "question = \"What are major topics for this class?\"\n",
                "\n",
                "docs_svm = svm_retriever.get_relevant_documents(question)\n",
                "docs_svm[0]"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Document(page_content='don\\'t have a MATLAB license, for the purposes of  this class, there\\'s also — [inaudible] \\nwrite that down [inaudible] MATLAB — there\\' s also a software package called Octave \\nthat you can download for free off the Internet. And it has somewhat fewer features than MATLAB, but it\\'s free, and for the purposes of  this class, it will work for just about \\neverything.  \\nSo actually I, well, so yeah, just a side comment for those of you that haven\\'t seen \\nMATLAB before I guess, once a colleague of mine at a different university, not at \\nStanford, actually teaches another machine l earning course. He\\'s taught it for many years. \\nSo one day, he was in his office, and an old student of his from, lik e, ten years ago came \\ninto his office and he said, \"Oh, professo r, professor, thank you so much for your \\nmachine learning class. I learned so much from it. There\\'s this stuff that I learned in your \\nclass, and I now use every day. And it\\'s help ed me make lots of money, and here\\'s a \\npicture of my big house.\"  \\nSo my friend was very excited. He said, \"W ow. That\\'s great. I\\'m glad to hear this \\nmachine learning stuff was actually useful. So what was it that you learned? Was it \\nlogistic regression? Was it the PCA? Was it the data ne tworks? What was it that you \\nlearned that was so helpful?\" And the student said, \"Oh, it was the MATLAB.\"  \\nSo for those of you that don\\'t know MATLAB yet, I hope you do learn it. It\\'s not hard,', metadata={})\n",
                "\n",
                "## TFIDF retriever {.smaller}"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "question = \"what did they say about matlab?\"\n",
                "\n",
                "docs_tfidf = tfidf_retriever.get_relevant_documents(question)\n",
                "\n",
                "docs_tfidf[0]"
            ],
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "language": "python",
            "display_name": "Python 3 (ipykernel)"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}