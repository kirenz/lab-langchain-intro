[
  {
    "objectID": "requirements.html",
    "href": "requirements.html",
    "title": "Requirements",
    "section": "",
    "text": "To start this lab, you‚Äôll need the following environments:\n\n\n\n\n\n\nImportant\n\n\n\nVisit the ‚ÄúProgramming Toolkit-webpage‚Äù to learn how to meet all requirements.\n\n\n\nSQL: MySQL, MySQL Workbench and a database called db_data\nPython: Anaconda, Anaconda Environment lab and Visual Studio Code\nEnvironment: A folder on your machine called competitive and an environment file with your MySQL password"
  },
  {
    "objectID": "slides/01_document_loading.html#python",
    "href": "slides/01_document_loading.html#python",
    "title": "Document Loading",
    "section": "Python",
    "text": "Python\n\nfrom langchain.document_loaders import NotionDirectoryLoader\nfrom langchain.document_loaders import WebBaseLoader\nimport pandas as pd\nfrom langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader\nfrom langchain.document_loaders.parsers import OpenAIWhisperParser\nfrom langchain.document_loaders.generic import GenericLoader\nfrom langchain.document_loaders import PyPDFLoader\nfrom dotenv import load_dotenv, find_dotenv\nimport os\nimport openai\n# import sys\n# sys.path.append('../..')\n\n_ = load_dotenv(find_dotenv())  # read local .env file\n\nopenai.api_key = os.environ['OPENAI_API_KEY']"
  },
  {
    "objectID": "slides/01_document_loading.html#basics",
    "href": "slides/01_document_loading.html#basics",
    "title": "Document Loading",
    "section": "Basics",
    "text": "Basics\n\nIn retrieval augmented generation (RAG), an LLM retrieves contextual documents from an external dataset as part of its execution.\nThis is useful if we want to ask question about specific documents (e.g., our PDFs, a set of videos, etc)."
  },
  {
    "objectID": "slides/01_document_loading.html#example",
    "href": "slides/01_document_loading.html#example",
    "title": "Document Loading",
    "section": "Example",
    "text": "Example\n\nLet‚Äôs load a PDF transcript from one of Andrew Ng‚Äôs courses\nThese documents are the result of automated transcription so words and sentences are sometimes split unexpectedly."
  },
  {
    "objectID": "slides/01_document_loading.html#load-pdf",
    "href": "slides/01_document_loading.html#load-pdf",
    "title": "Document Loading",
    "section": "Load PDF",
    "text": "Load PDF\n\nloader = PyPDFLoader(\"../docs/cs229_lectures/MachineLearning-Lecture01.pdf\")\npages = loader.load()\n\n\nEach page is a Document.\nA Document contains text (page_content) and metadata."
  },
  {
    "objectID": "slides/01_document_loading.html#inspect-data",
    "href": "slides/01_document_loading.html#inspect-data",
    "title": "Document Loading",
    "section": "Inspect data",
    "text": "Inspect data\n\nlen(pages)\n\n\n\n\n22 . . .\n\npage = pages[0]\n\n\n\npage.metadata\n\n\n\n\n\n{‚Äòsource‚Äô: ‚Äò../docs/cs229_lectures/MachineLearning-Lecture01.pdf‚Äô, ‚Äòpage‚Äô: 0}"
  },
  {
    "objectID": "slides/01_document_loading.html#inspect-content",
    "href": "slides/01_document_loading.html#inspect-content",
    "title": "Document Loading",
    "section": "Inspect content",
    "text": "Inspect content\n\nprint(page.page_content[0:500])\n\n\n\n\n\nMachineLearning-Lecture01\nInstructor (Andrew Ng): Okay. Good morning. Welcome to CS229, the machine learning class. So what I wanna do today is ju st spend a little time going over the logistics of the class, and then we‚Äôll start to talk a bit about machine learning.\nBy way of introduction, my name‚Äôs Andrew Ng and I‚Äôll be instru ctor for this class. And so I personally work in machine learning, and I‚Äô ve worked on it for about 15 years now, and I actually think that machine learning i"
  },
  {
    "objectID": "slides/01_document_loading.html#prerequisites",
    "href": "slides/01_document_loading.html#prerequisites",
    "title": "Document Loading",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nYou need FFmpeg\nMac: install with Homebrew"
  },
  {
    "objectID": "slides/01_document_loading.html#example-1",
    "href": "slides/01_document_loading.html#example-1",
    "title": "Document Loading",
    "section": "Example",
    "text": "Example\nLet‚Äôs load the ‚ÄúCode Report‚Äù about Vector databases from Fireship"
  },
  {
    "objectID": "slides/01_document_loading.html#load-youtube-video",
    "href": "slides/01_document_loading.html#load-youtube-video",
    "title": "Document Loading",
    "section": "Load YouTube video",
    "text": "Load YouTube video\n\n# link to video\nurl = \"https://www.youtube.com/watch?v=klTvEwg3oJ4\"\n\n# path to directory\nsave_dir = \"../docs/youtube/\"\n\n# load video\nloader = GenericLoader(\n    YoutubeAudioLoader([url], save_dir),\n    OpenAIWhisperParser()\n)\n\ndocs = loader.load()"
  },
  {
    "objectID": "slides/01_document_loading.html#inspect-data-1",
    "href": "slides/01_document_loading.html#inspect-data-1",
    "title": "Document Loading",
    "section": "Inspect data",
    "text": "Inspect data\n\ndocs[0].page_content[0:500]\n\n\n\n\n\n‚ÄúIt is April 7th, 2023, and you‚Äôre watching The Code Report. One month ago, Vector Database Weaviate landed $16 million in Series A funding. Last week, PineconeDB just got a check for $28 million at a $700 million valuation. And yesterday, Chroma, an open source project with only 1.2 GitHub stars, raised $18 million for its Embeddings database. And I just launched my own Vector database this morning. We‚Äôre currently pre-revenue, pre-vision, and pre-code, and valued at $420 million. Leave your cre‚Äù"
  },
  {
    "objectID": "slides/01_document_loading.html#save-as-dataframe",
    "href": "slides/01_document_loading.html#save-as-dataframe",
    "title": "Document Loading",
    "section": "Save as DataFrame",
    "text": "Save as DataFrame\n\ndf = pd.DataFrame(docs, columns=['Text', 'Metadata'])"
  },
  {
    "objectID": "slides/01_document_loading.html#save-as-csv",
    "href": "slides/01_document_loading.html#save-as-csv",
    "title": "Document Loading",
    "section": "Save as CSV",
    "text": "Save as CSV\n\ndf.to_csv('../docs/youtube/codereport.csv')"
  },
  {
    "objectID": "slides/01_document_loading.html#example-2",
    "href": "slides/01_document_loading.html#example-2",
    "title": "Document Loading",
    "section": "Example",
    "text": "Example\n\nLet‚Äôs load a page from ‚ÄúIntroduction to Modern Statistics‚Äù by Mine √áetinkaya-Rundel and Johanna Hardin: https://openintro-ims.netlify.app/data-design\nThe raw file is provided in GutHub under this URL: https://raw.githubusercontent.com/OpenIntroStat/ims/main/02-data-design.qmd"
  },
  {
    "objectID": "slides/01_document_loading.html#load-url",
    "href": "slides/01_document_loading.html#load-url",
    "title": "Document Loading",
    "section": "Load URL",
    "text": "Load URL\n\nloader = WebBaseLoader(\n    \"https://raw.githubusercontent.com/OpenIntroStat/ims/main/02-data-design.qmd\")\n\ndocs = loader.load()"
  },
  {
    "objectID": "slides/01_document_loading.html#inspact-data",
    "href": "slides/01_document_loading.html#inspact-data",
    "title": "Document Loading",
    "section": "Inspact data",
    "text": "Inspact data\n\nprint(docs[0].page_content[400:800])\n\n\n\n\n\nampling. Knowing how the observational units were selected from a larger entity will allow for generalizations back to the population from which the data were randomly selected. Additionally, by understanding the structure of the study, causal relationships can be separated from those relationships which are only associated. A good question to ask oneself before working with the data at all is, ‚ÄúH"
  },
  {
    "objectID": "slides/01_document_loading.html#save-as-dataframe-1",
    "href": "slides/01_document_loading.html#save-as-dataframe-1",
    "title": "Document Loading",
    "section": "Save as DataFrame",
    "text": "Save as DataFrame\n\ndf = pd.DataFrame(docs, columns=['Text', 'Metadata'])"
  },
  {
    "objectID": "slides/01_document_loading.html#save-as-csv-1",
    "href": "slides/01_document_loading.html#save-as-csv-1",
    "title": "Document Loading",
    "section": "Save as CSV",
    "text": "Save as CSV\n\ndf.to_csv('../docs/url/study-design.csv')"
  },
  {
    "objectID": "slides/01_document_loading.html#example-3",
    "href": "slides/01_document_loading.html#example-3",
    "title": "Document Loading",
    "section": "Example",
    "text": "Example\n\nFollow the steps here for an example Notion site such as this one:\nDuplicate the page into your own Notion space and export as Markdown / CSV.\nUnzip it and save it as a folder that contains the markdown file for the Notion page."
  },
  {
    "objectID": "slides/01_document_loading.html#load-notion",
    "href": "slides/01_document_loading.html#load-notion",
    "title": "Document Loading",
    "section": "Load Notion",
    "text": "Load Notion\n\nloader = NotionDirectoryLoader(\"../docs/Notion_DB\")\ndocs = loader.load()"
  },
  {
    "objectID": "slides/01_document_loading.html#inspect-data-2",
    "href": "slides/01_document_loading.html#inspect-data-2",
    "title": "Document Loading",
    "section": "Inspect data",
    "text": "Inspect data\n\nprint(docs[0].page_content[0:200])\n\n\n\n\n# Getting Started\n\nüëã Welcome to Notion!\n\nHere are the basics:\n\n- [ ]  Click anywhere and just start typing\n- [ ]  Hit `/` to see all the types of content you can add - headers, videos, sub pages, etc."
  },
  {
    "objectID": "slides/01_document_loading.html#inspect-data-3",
    "href": "slides/01_document_loading.html#inspect-data-3",
    "title": "Document Loading",
    "section": "Inspect data",
    "text": "Inspect data\n\ndocs[0].metadata\n\n\n\n\n\n{‚Äòsource‚Äô: ‚Äò../docs/Notion_DB/Getting Started 95e5ecbe48c44e408ef09fed850fbd40.md‚Äô}"
  },
  {
    "objectID": "slides/03_vectorstores_and_embeddings.html",
    "href": "slides/03_vectorstores_and_embeddings.html",
    "title": "Vectorstores and Embeddings",
    "section": "",
    "text": "Recall the overall workflow for retrieval augmented generation (RAG):\nimport os\nimport openai\nimport sys\nsys.path.append('../..')\n\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv()) # read local .env file\n\nopenai.api_key  = os.environ['OPENAI_API_KEY']\nWe just discussed Document Loading and Splitting.\nfrom langchain.document_loaders import PyPDFLoader\n\n# Load PDF\nloaders = [\n    # Duplicate documents on purpose - messy data\n    PyPDFLoader(\"docs/cs229_lectures/MachineLearning-Lecture01.pdf\"),\n    PyPDFLoader(\"docs/cs229_lectures/MachineLearning-Lecture01.pdf\"),\n    PyPDFLoader(\"docs/cs229_lectures/MachineLearning-Lecture02.pdf\"),\n    PyPDFLoader(\"docs/cs229_lectures/MachineLearning-Lecture03.pdf\")\n]\ndocs = []\nfor loader in loaders:\n    docs.extend(loader.load())\n# Split\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\ntext_splitter = RecursiveCharacterTextSplitter(\n    chunk_size = 1500,\n    chunk_overlap = 150\n)\nsplits = text_splitter.split_documents(docs)\nlen(splits)\n\n209"
  },
  {
    "objectID": "slides/03_vectorstores_and_embeddings.html#embeddings",
    "href": "slides/03_vectorstores_and_embeddings.html#embeddings",
    "title": "Vectorstores and Embeddings",
    "section": "Embeddings",
    "text": "Embeddings\nLet‚Äôs take our splits and embed them.\n\nfrom langchain.embeddings.openai import OpenAIEmbeddings\nembedding = OpenAIEmbeddings()\n\n\nsentence1 = \"i like dogs\"\nsentence2 = \"i like canines\"\nsentence3 = \"the weather is ugly outside\"\n\n\nembedding1 = embedding.embed_query(sentence1)\nembedding2 = embedding.embed_query(sentence2)\nembedding3 = embedding.embed_query(sentence3)\n\n\nimport numpy as np\n\n\nnp.dot(embedding1, embedding2)\n\n0.9632061931217912\n\n\n\nnp.dot(embedding1, embedding3)\n\n0.7710930628043693\n\n\n\nnp.dot(embedding2, embedding3)\n\n0.7596334120325541"
  },
  {
    "objectID": "slides/03_vectorstores_and_embeddings.html#vectorstores",
    "href": "slides/03_vectorstores_and_embeddings.html#vectorstores",
    "title": "Vectorstores and Embeddings",
    "section": "Vectorstores",
    "text": "Vectorstores\n\n# ! pip install chromadb\n\n\nfrom langchain.vectorstores import Chroma\n\n\npersist_directory = 'docs/chroma/'\n\n\n!rm -rf ./docs/chroma  # remove old database files if any\n\n\nvectordb = Chroma.from_documents(\n    documents=splits,\n    embedding=embedding,\n    persist_directory=persist_directory\n)\n\n\nprint(vectordb._collection.count())\n\n209\n\n\n\nSimilarity Search\n\nquestion = \"is there an email i can ask for help\"\n\n\ndocs = vectordb.similarity_search(question,k=3)\n\n\nlen(docs)\n\n3\n\n\n\ndocs[0].page_content\n\n\"cs229-qa@cs.stanford.edu. This goes to an acc ount that's read by all the TAs and me. So \\nrather than sending us email individually, if you send email to this account, it will \\nactually let us get back to you maximally quickly with answers to your questions.  \\nIf you're asking questions about homework probl ems, please say in the subject line which \\nassignment and which question the email refers to, since that will also help us to route \\nyour question to the appropriate TA or to me  appropriately and get the response back to \\nyou quickly.  \\nLet's see. Skipping ahead ‚Äî let's see ‚Äî for homework, one midterm, one open and term \\nproject. Notice on the honor code. So one thi ng that I think will help you to succeed and \\ndo well in this class and even help you to enjoy this cla ss more is if you form a study \\ngroup.  \\nSo start looking around where you' re sitting now or at the end of class today, mingle a \\nlittle bit and get to know your classmates. I strongly encourage you to form study groups \\nand sort of have a group of people to study with and have a group of your fellow students \\nto talk over these concepts with. You can also  post on the class news group if you want to \\nuse that to try to form a study group.  \\nBut some of the problems sets in this cla ss are reasonably difficult.  People that have \\ntaken the class before may tell you they were very difficult. And just I bet it would be \\nmore fun for you, and you'd probably have a be tter learning experience if you form a\"\n\n\nLet‚Äôs save this so we can use it later!\n\nvectordb.persist()"
  },
  {
    "objectID": "slides/03_vectorstores_and_embeddings.html#failure-modes",
    "href": "slides/03_vectorstores_and_embeddings.html#failure-modes",
    "title": "Vectorstores and Embeddings",
    "section": "Failure modes",
    "text": "Failure modes\nThis seems great, and basic similarity search will get you 80% of the way there very easily.\nBut there are some failure modes that can creep up.\nHere are some edge cases that can arise - we‚Äôll fix them in the next class.\n\nquestion = \"what did they say about matlab?\"\n\n\ndocs = vectordb.similarity_search(question,k=5)\n\nNotice that we‚Äôre getting duplicate chunks (because of the duplicate MachineLearning-Lecture01.pdf in the index).\nSemantic search fetches all similar documents, but does not enforce diversity.\ndocs[0] and docs[1] are indentical.\n\ndocs[0]\n\nDocument(page_content='those homeworks will be done in either MATLA B or in Octave, which is sort of ‚Äî I \\nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn\\'t.  \\nSo I guess for those of you that haven\\'t s een MATLAB before, and I know most of you \\nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \\nplot data. And it\\'s sort of an extremely easy to  learn tool to use for implementing a lot of \\nlearning algorithms.  \\nAnd in case some of you want to work on your  own home computer or something if you \\ndon\\'t have a MATLAB license, for the purposes of  this class, there\\'s also ‚Äî [inaudible] \\nwrite that down [inaudible] MATLAB ‚Äî there\\' s also a software package called Octave \\nthat you can download for free off the Internet. And it has somewhat fewer features than MATLAB, but it\\'s free, and for the purposes of  this class, it will work for just about \\neverything.  \\nSo actually I, well, so yeah, just a side comment for those of you that haven\\'t seen \\nMATLAB before I guess, once a colleague of mine at a different university, not at \\nStanford, actually teaches another machine l earning course. He\\'s taught it for many years. \\nSo one day, he was in his office, and an old student of his from, lik e, ten years ago came \\ninto his office and he said, \"Oh, professo r, professor, thank you so much for your', metadata={'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf', 'page': 8})\n\n\n\ndocs[1]\n\nDocument(page_content='those homeworks will be done in either MATLA B or in Octave, which is sort of ‚Äî I \\nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn\\'t.  \\nSo I guess for those of you that haven\\'t s een MATLAB before, and I know most of you \\nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \\nplot data. And it\\'s sort of an extremely easy to  learn tool to use for implementing a lot of \\nlearning algorithms.  \\nAnd in case some of you want to work on your  own home computer or something if you \\ndon\\'t have a MATLAB license, for the purposes of  this class, there\\'s also ‚Äî [inaudible] \\nwrite that down [inaudible] MATLAB ‚Äî there\\' s also a software package called Octave \\nthat you can download for free off the Internet. And it has somewhat fewer features than MATLAB, but it\\'s free, and for the purposes of  this class, it will work for just about \\neverything.  \\nSo actually I, well, so yeah, just a side comment for those of you that haven\\'t seen \\nMATLAB before I guess, once a colleague of mine at a different university, not at \\nStanford, actually teaches another machine l earning course. He\\'s taught it for many years. \\nSo one day, he was in his office, and an old student of his from, lik e, ten years ago came \\ninto his office and he said, \"Oh, professo r, professor, thank you so much for your', metadata={'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf', 'page': 8})\n\n\nWe can see a new failure mode.\nThe question below asks a question about the third lecture, but includes results from other lectures as well.\n\nquestion = \"what did they say about regression in the third lecture?\"\n\n\ndocs = vectordb.similarity_search(question,k=5)\n\n\nfor doc in docs:\n    print(doc.metadata)\n\n{'source': 'docs/cs229_lectures/MachineLearning-Lecture03.pdf', 'page': 0}\n{'source': 'docs/cs229_lectures/MachineLearning-Lecture03.pdf', 'page': 14}\n{'source': 'docs/cs229_lectures/MachineLearning-Lecture02.pdf', 'page': 0}\n{'source': 'docs/cs229_lectures/MachineLearning-Lecture03.pdf', 'page': 6}\n{'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf', 'page': 8}\n\n\n\nprint(docs[4].page_content)\n\ninto his office and he said, \"Oh, professo r, professor, thank you so much for your \nmachine learning class. I learned so much from it. There's this stuff that I learned in your \nclass, and I now use every day. And it's help ed me make lots of money, and here's a \npicture of my big house.\"  \nSo my friend was very excited. He said, \"W ow. That's great. I'm glad to hear this \nmachine learning stuff was actually useful. So what was it that you learned? Was it \nlogistic regression? Was it the PCA? Was it the data ne tworks? What was it that you \nlearned that was so helpful?\" And the student said, \"Oh, it was the MATLAB.\"  \nSo for those of you that don't know MATLAB yet, I hope you do learn it. It's not hard, \nand we'll actually have a short MATLAB tutori al in one of the discussion sections for \nthose of you that don't know it.  \nOkay. The very last piece of logistical th ing is the discussion s ections. So discussion \nsections will be taught by the TAs, and atte ndance at discussion sections is optional, \nalthough they'll also be recorded and televi sed. And we'll use the discussion sections \nmainly for two things. For the next two or th ree weeks, we'll use the discussion sections \nto go over the prerequisites to this class or if some of you haven't seen probability or \nstatistics for a while or maybe algebra, we'll go over those in the discussion sections as a \nrefresher for those of you that want one.\n\n\nApproaches discussed in the next lecture can be used to address both!"
  },
  {
    "objectID": "slides/05_question_answering.html",
    "href": "slides/05_question_answering.html",
    "title": "Question Answering",
    "section": "",
    "text": "Recall the overall workflow for retrieval augmented generation (RAG):\n\n\n\noverview.jpeg\n\n\nWe discussed Document Loading and Splitting as well as Storage and Retrieval.\nLet‚Äôs load our vectorDB.\n\nimport os\nimport openai\nimport sys\nsys.path.append('../..')\n\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv()) # read local .env file\n\nopenai.api_key  = os.environ['OPENAI_API_KEY']\n\nThe code below was added to assign the openai LLM version filmed until it is deprecated, currently in Sept 2023. LLM responses can often vary, but the responses may be significantly different when using a different model version.\n\nimport datetime\ncurrent_date = datetime.datetime.now().date()\nif current_date &lt; datetime.date(2023, 9, 2):\n    llm_name = \"gpt-3.5-turbo-0301\"\nelse:\n    llm_name = \"gpt-3.5-turbo\"\nprint(llm_name)\n\ngpt-3.5-turbo-0301\n\n\n\nfrom langchain.vectorstores import Chroma\nfrom langchain.embeddings.openai import OpenAIEmbeddings\npersist_directory = 'docs/chroma/'\nembedding = OpenAIEmbeddings()\nvectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)\n\n\nprint(vectordb._collection.count())\n\n209\n\n\n\nquestion = \"What are major topics for this class?\"\ndocs = vectordb.similarity_search(question,k=3)\nlen(docs)\n\n3\n\n\n\nfrom langchain.chat_models import ChatOpenAI\nllm = ChatOpenAI(model_name=llm_name, temperature=0)\n\n\n\n\nfrom langchain.chains import RetrievalQA\n\n\nqa_chain = RetrievalQA.from_chain_type(\n    llm,\n    retriever=vectordb.as_retriever()\n)\n\n\nresult = qa_chain({\"query\": question})\n\n\nresult[\"result\"]\n\n'The major topic for this class is machine learning. Additionally, the class may cover statistics and algebra as refreshers in the discussion sections. Later in the quarter, the discussion sections will also cover extensions for the material taught in the main lectures.'\n\n\n\n\n\n\nfrom langchain.prompts import PromptTemplate\n\n# Build prompt\ntemplate = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer. \n{context}\nQuestion: {question}\nHelpful Answer:\"\"\"\nQA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n\n\n# Run chain\nqa_chain = RetrievalQA.from_chain_type(\n    llm,\n    retriever=vectordb.as_retriever(),\n    return_source_documents=True,\n    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n)\n\n\nquestion = \"Is probability a class topic?\"\n\n\nresult = qa_chain({\"query\": question})\n\n\nresult[\"result\"]\n\n'Yes, probability is assumed to be a prerequisite for this class. The instructor assumes familiarity with basic probability and statistics, and will go over some of the prerequisites in the discussion sections as a refresher course. Thanks for asking!'\n\n\n\nresult[\"source_documents\"][0]\n\nDocument(page_content=\"of this class will not be very program ming intensive, although we will do some \\nprogramming, mostly in either MATLAB or Octa ve. I'll say a bit more about that later.  \\nI also assume familiarity with basic proba bility and statistics. So most undergraduate \\nstatistics class, like Stat 116 taught here at Stanford, will be more than enough. I'm gonna \\nassume all of you know what ra ndom variables are, that all of you know what expectation \\nis, what a variance or a random variable is. And in case of some of you, it's been a while \\nsince you've seen some of this material. At some of the discussion sections, we'll actually \\ngo over some of the prerequisites, sort of as  a refresher course under prerequisite class. \\nI'll say a bit more about that later as well.  \\nLastly, I also assume familiarity with basi c linear algebra. And again, most undergraduate \\nlinear algebra courses are more than enough. So if you've taken courses like Math 51, \\n103, Math 113 or CS205 at Stanford, that would be more than enough. Basically, I'm \\ngonna assume that all of you know what matrix es and vectors are, that you know how to \\nmultiply matrices and vectors and multiply matrix and matrices, that you know what a matrix inverse is. If you know what an eigenvect or of a matrix is, that'd be even better. \\nBut if you don't quite know or if you're not qu ite sure, that's fine, too. We'll go over it in \\nthe review sections.\", metadata={'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf', 'page': 4})\n\n\n\n\n\n\nqa_chain_mr = RetrievalQA.from_chain_type(\n    llm,\n    retriever=vectordb.as_retriever(),\n    chain_type=\"map_reduce\"\n)\n\n\nresult = qa_chain_mr({\"query\": question})\n\n\nresult[\"result\"]\n\n'There is no clear answer to this question based on the given portion of the document. The document mentions familiarity with basic probability and statistics as a prerequisite for the class, and there is a brief mention of probability in the text, but it is not clear if it is a main topic of the class. The instructor mentions using a probabilistic interpretation to derive a learning algorithm, but does not go into further detail about probability as a topic.'\n\n\nIf you wish to experiment on the LangChain plus platform:\n\nGo to langchain plus platform and sign up\nCreate an API key from your account‚Äôs settings\nUse this API key in the code below\n\nuncomment the code\nNote, the endpoint in the video differs from the one below. Use the one below.\n\n\nimport os\nos.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\nos.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.langchain.plus\"\nos.environ[\"LANGCHAIN_API_KEY\"] = \"...\" # replace dots with your api key\n\n\nqa_chain_mr = RetrievalQA.from_chain_type(\n    llm,\n    retriever=vectordb.as_retriever(),\n    chain_type=\"map_reduce\"\n)\nresult = qa_chain_mr({\"query\": question})\nresult[\"result\"]\n\n'There is no clear answer to this question based on the given portion of the document. The document mentions familiarity with basic probability and statistics as a prerequisite for the class, and there is a brief mention of probability in the text, but it is not clear if it is a main topic of the class.'\n\n\n\nqa_chain_mr = RetrievalQA.from_chain_type(\n    llm,\n    retriever=vectordb.as_retriever(),\n    chain_type=\"refine\"\n)\nresult = qa_chain_mr({\"query\": question})\nresult[\"result\"]\n\n\"Based on the additional context provided, probability is not the main focus of the class, but rather a tool used in the development of machine learning algorithms. The main topics of the class seem to be related to machine learning algorithms, including linear regression and classification, and their applications in various fields such as medical diagnosis and housing market prediction. The instructor mentions that they will go over statistics and algebra in the discussion sections as a refresher for those who need it. Additionally, the discussion sections will be used to cover extensions for the material taught in the main lectures, as there are several extensions that the instructor wants to teach but didn't have time for in the main lectures.\"\n\n\n\n\n\nQA fails to preserve conversational history.\n\nqa_chain = RetrievalQA.from_chain_type(\n    llm,\n    retriever=vectordb.as_retriever()\n)\n\n\nquestion = \"Is probability a class topic?\"\nresult = qa_chain({\"query\": question})\nresult[\"result\"]\n\n'Yes, probability is a topic that will be assumed to be familiar to students in this class. The instructor mentions that basic probability and statistics are prerequisites for the class and assumes that most undergraduate statistics classes, like Stat 116 taught at Stanford, will be more than enough.'\n\n\n\nquestion = \"why are those prerequesites needed?\"\nresult = qa_chain({\"query\": question})\nresult[\"result\"]\n\n'The prerequisites are needed because in this class, the instructor assumes that all students have a basic knowledge of computer science and knowledge of basic computer skills and principles. This includes knowledge of big-O notation and linear algebra, which are important concepts in machine learning. Without this basic knowledge, it may be difficult for students to understand the material covered in the class.'\n\n\nNote, The LLM response varies. Some responses do include a reference to probability which might be gleaned from referenced documents. The point is simply that the model does not have access to past questions or answers, this will be covered in the next section."
  },
  {
    "objectID": "slides/05_question_answering.html#overview",
    "href": "slides/05_question_answering.html#overview",
    "title": "Question Answering",
    "section": "",
    "text": "Recall the overall workflow for retrieval augmented generation (RAG):\n\n\n\noverview.jpeg\n\n\nWe discussed Document Loading and Splitting as well as Storage and Retrieval.\nLet‚Äôs load our vectorDB.\n\nimport os\nimport openai\nimport sys\nsys.path.append('../..')\n\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv()) # read local .env file\n\nopenai.api_key  = os.environ['OPENAI_API_KEY']\n\nThe code below was added to assign the openai LLM version filmed until it is deprecated, currently in Sept 2023. LLM responses can often vary, but the responses may be significantly different when using a different model version.\n\nimport datetime\ncurrent_date = datetime.datetime.now().date()\nif current_date &lt; datetime.date(2023, 9, 2):\n    llm_name = \"gpt-3.5-turbo-0301\"\nelse:\n    llm_name = \"gpt-3.5-turbo\"\nprint(llm_name)\n\ngpt-3.5-turbo-0301\n\n\n\nfrom langchain.vectorstores import Chroma\nfrom langchain.embeddings.openai import OpenAIEmbeddings\npersist_directory = 'docs/chroma/'\nembedding = OpenAIEmbeddings()\nvectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)\n\n\nprint(vectordb._collection.count())\n\n209\n\n\n\nquestion = \"What are major topics for this class?\"\ndocs = vectordb.similarity_search(question,k=3)\nlen(docs)\n\n3\n\n\n\nfrom langchain.chat_models import ChatOpenAI\nllm = ChatOpenAI(model_name=llm_name, temperature=0)\n\n\n\n\nfrom langchain.chains import RetrievalQA\n\n\nqa_chain = RetrievalQA.from_chain_type(\n    llm,\n    retriever=vectordb.as_retriever()\n)\n\n\nresult = qa_chain({\"query\": question})\n\n\nresult[\"result\"]\n\n'The major topic for this class is machine learning. Additionally, the class may cover statistics and algebra as refreshers in the discussion sections. Later in the quarter, the discussion sections will also cover extensions for the material taught in the main lectures.'\n\n\n\n\n\n\nfrom langchain.prompts import PromptTemplate\n\n# Build prompt\ntemplate = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer. \n{context}\nQuestion: {question}\nHelpful Answer:\"\"\"\nQA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n\n\n# Run chain\nqa_chain = RetrievalQA.from_chain_type(\n    llm,\n    retriever=vectordb.as_retriever(),\n    return_source_documents=True,\n    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n)\n\n\nquestion = \"Is probability a class topic?\"\n\n\nresult = qa_chain({\"query\": question})\n\n\nresult[\"result\"]\n\n'Yes, probability is assumed to be a prerequisite for this class. The instructor assumes familiarity with basic probability and statistics, and will go over some of the prerequisites in the discussion sections as a refresher course. Thanks for asking!'\n\n\n\nresult[\"source_documents\"][0]\n\nDocument(page_content=\"of this class will not be very program ming intensive, although we will do some \\nprogramming, mostly in either MATLAB or Octa ve. I'll say a bit more about that later.  \\nI also assume familiarity with basic proba bility and statistics. So most undergraduate \\nstatistics class, like Stat 116 taught here at Stanford, will be more than enough. I'm gonna \\nassume all of you know what ra ndom variables are, that all of you know what expectation \\nis, what a variance or a random variable is. And in case of some of you, it's been a while \\nsince you've seen some of this material. At some of the discussion sections, we'll actually \\ngo over some of the prerequisites, sort of as  a refresher course under prerequisite class. \\nI'll say a bit more about that later as well.  \\nLastly, I also assume familiarity with basi c linear algebra. And again, most undergraduate \\nlinear algebra courses are more than enough. So if you've taken courses like Math 51, \\n103, Math 113 or CS205 at Stanford, that would be more than enough. Basically, I'm \\ngonna assume that all of you know what matrix es and vectors are, that you know how to \\nmultiply matrices and vectors and multiply matrix and matrices, that you know what a matrix inverse is. If you know what an eigenvect or of a matrix is, that'd be even better. \\nBut if you don't quite know or if you're not qu ite sure, that's fine, too. We'll go over it in \\nthe review sections.\", metadata={'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf', 'page': 4})\n\n\n\n\n\n\nqa_chain_mr = RetrievalQA.from_chain_type(\n    llm,\n    retriever=vectordb.as_retriever(),\n    chain_type=\"map_reduce\"\n)\n\n\nresult = qa_chain_mr({\"query\": question})\n\n\nresult[\"result\"]\n\n'There is no clear answer to this question based on the given portion of the document. The document mentions familiarity with basic probability and statistics as a prerequisite for the class, and there is a brief mention of probability in the text, but it is not clear if it is a main topic of the class. The instructor mentions using a probabilistic interpretation to derive a learning algorithm, but does not go into further detail about probability as a topic.'\n\n\nIf you wish to experiment on the LangChain plus platform:\n\nGo to langchain plus platform and sign up\nCreate an API key from your account‚Äôs settings\nUse this API key in the code below\n\nuncomment the code\nNote, the endpoint in the video differs from the one below. Use the one below.\n\n\nimport os\nos.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\nos.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.langchain.plus\"\nos.environ[\"LANGCHAIN_API_KEY\"] = \"...\" # replace dots with your api key\n\n\nqa_chain_mr = RetrievalQA.from_chain_type(\n    llm,\n    retriever=vectordb.as_retriever(),\n    chain_type=\"map_reduce\"\n)\nresult = qa_chain_mr({\"query\": question})\nresult[\"result\"]\n\n'There is no clear answer to this question based on the given portion of the document. The document mentions familiarity with basic probability and statistics as a prerequisite for the class, and there is a brief mention of probability in the text, but it is not clear if it is a main topic of the class.'\n\n\n\nqa_chain_mr = RetrievalQA.from_chain_type(\n    llm,\n    retriever=vectordb.as_retriever(),\n    chain_type=\"refine\"\n)\nresult = qa_chain_mr({\"query\": question})\nresult[\"result\"]\n\n\"Based on the additional context provided, probability is not the main focus of the class, but rather a tool used in the development of machine learning algorithms. The main topics of the class seem to be related to machine learning algorithms, including linear regression and classification, and their applications in various fields such as medical diagnosis and housing market prediction. The instructor mentions that they will go over statistics and algebra in the discussion sections as a refresher for those who need it. Additionally, the discussion sections will be used to cover extensions for the material taught in the main lectures, as there are several extensions that the instructor wants to teach but didn't have time for in the main lectures.\"\n\n\n\n\n\nQA fails to preserve conversational history.\n\nqa_chain = RetrievalQA.from_chain_type(\n    llm,\n    retriever=vectordb.as_retriever()\n)\n\n\nquestion = \"Is probability a class topic?\"\nresult = qa_chain({\"query\": question})\nresult[\"result\"]\n\n'Yes, probability is a topic that will be assumed to be familiar to students in this class. The instructor mentions that basic probability and statistics are prerequisites for the class and assumes that most undergraduate statistics classes, like Stat 116 taught at Stanford, will be more than enough.'\n\n\n\nquestion = \"why are those prerequesites needed?\"\nresult = qa_chain({\"query\": question})\nresult[\"result\"]\n\n'The prerequisites are needed because in this class, the instructor assumes that all students have a basic knowledge of computer science and knowledge of basic computer skills and principles. This includes knowledge of big-O notation and linear algebra, which are important concepts in machine learning. Without this basic knowledge, it may be difficult for students to understand the material covered in the class.'\n\n\nNote, The LLM response varies. Some responses do include a reference to probability which might be gleaned from referenced documents. The point is simply that the model does not have access to past questions or answers, this will be covered in the next section."
  },
  {
    "objectID": "docs/Notion_DB/Getting Started 95e5ecbe48c44e408ef09fed850fbd40.html",
    "href": "docs/Notion_DB/Getting Started 95e5ecbe48c44e408ef09fed850fbd40.html",
    "title": "Getting Started",
    "section": "",
    "text": "Getting Started\nüëã Welcome to Notion!\nHere are the basics:\n\nClick anywhere and just start typing\nHit / to see all the types of content you can add - headers, videos, sub pages, etc.\nExample sub page\nHighlight any text, and use the menu that pops up to style your writing however you like\nSee the ‚ãÆ‚ãÆ to the left of this checkbox on hover? Click and drag to move this line\nClick the + New Page button at the bottom of your sidebar to add a new page\nClick Templates in your sidebar to get started with pre-built pages\nThis is a toggle block. Click the little triangle to see more useful tips!\n\nTemplate Gallery: More templates built by the Notion community\nHelp & Support: ****Guides and FAQs for everything in Notion\nStay organized with your sidebar and nested pages:\n\n\n\nGetting%20Started%2095e5ecbe48c44e408ef09fed850fbd40/infinitehierarchynodither.gif\n\n\n\n\nSee it in action:\n1 minute\n1 minute\n4 minutes\n4 minutes\n2 minutes\n2 minutes\n2 minutes\n2 minutes\nVisit our YouTube channel to watch 50+ more tutorials\nüëâHave a question? Click the ? at the bottom right for more guides, or to send us a message."
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "Assignments",
    "section": "",
    "text": "This is a Quarto slidedeck."
  },
  {
    "objectID": "slide.html",
    "href": "slide.html",
    "title": "Slides",
    "section": "",
    "text": "The following tutorials are mainly based on the excellent course ‚ÄúLangChain: Chat with Your DataI‚Äù provided by Harrison Chase from LangChain and Andrew Ng from DeepLearning.AI."
  },
  {
    "objectID": "slide.html#txt",
    "href": "slide.html#txt",
    "title": "Slides",
    "section": "1 Txt",
    "text": "1 Txt\nIn this tutorial, you‚Äôll learn:\n\n\n\n\n\n\n\nüñ•Ô∏è Presentation\nüíª Jupyter Notebook"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome üëã",
    "section": "",
    "text": "Welcome to the lab ‚ÄúLangchain intro‚Äù\nThe tutorials in this lab will cover Retrieval Augmented Generation (RAG), a common LLM application that retrieves contextual documents from an external dataset, and a guide to building a chatbot that responds to queries based on the content of your documents, rather than the information it has learned in training.\n\n\n\n\n\n\nImportant\n\n\n\nMake sure you meet all the requirements and have read the lecture slides before you start with the assignments\n\n\nWhat you will learn in this lab:\n\nDocument Loading: Learn the fundamentals of data loading and discover over 80 unique loaders LangChain provides to access diverse data sources, including audio and video.\nDocument Splitting: Discover the best practices and considerations for splitting data.\nVector stores and embeddings: Dive into the concept of embeddings and explore vector store integrations within LangChain.\nRetrieval: Grasp advanced techniques for accessing and indexing data in the vector store, enabling you to retrieve the most relevant information beyond semantic queries.\nQuestion Answering: Build a one-pass question-answering solution.\nChat: Learn how to track and select pertinent information from conversations and data sources, as you build your own chatbot using LangChain."
  },
  {
    "objectID": "code/notebook.html",
    "href": "code/notebook.html",
    "title": "Notebook",
    "section": "",
    "text": "Load Python libaries and API keys.\n\nimport os\nimport openai\nimport pandas as pd\nimport altair as alt\nfrom dotenv import load_dotenv, find_dotenv\n\n\n_ = load_dotenv(find_dotenv()) # read local .env file\nopenai.api_key  = os.environ['OPENAI_API_KEY']"
  },
  {
    "objectID": "code/notebook.html#setup",
    "href": "code/notebook.html#setup",
    "title": "Notebook",
    "section": "",
    "text": "Load Python libaries and API keys.\n\nimport os\nimport openai\nimport pandas as pd\nimport altair as alt\nfrom dotenv import load_dotenv, find_dotenv\n\n\n_ = load_dotenv(find_dotenv()) # read local .env file\nopenai.api_key  = os.environ['OPENAI_API_KEY']"
  },
  {
    "objectID": "code/notebook.html#data",
    "href": "code/notebook.html#data",
    "title": "Notebook",
    "section": "Data",
    "text": "Data"
  },
  {
    "objectID": "slides/02_document_splitting.html",
    "href": "slides/02_document_splitting.html",
    "title": "Document Splitting",
    "section": "",
    "text": "import os\nimport openai\nimport sys\nsys.path.append('../..')\n\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv()) # read local .env file\n\nopenai.api_key  = os.environ['OPENAI_API_KEY']\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\nchunk_size =26\nchunk_overlap = 4\nr_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=chunk_size,\n    chunk_overlap=chunk_overlap\n)\nc_splitter = CharacterTextSplitter(\n    chunk_size=chunk_size,\n    chunk_overlap=chunk_overlap\n)\nWhy doesn‚Äôt this split the string below?\ntext1 = 'abcdefghijklmnopqrstuvwxyz'\nr_splitter.split_text(text1)\n\n['abcdefghijklmnopqrstuvwxyz']\ntext2 = 'abcdefghijklmnopqrstuvwxyzabcdefg'\nr_splitter.split_text(text2)\n\n['abcdefghijklmnopqrstuvwxyz', 'wxyzabcdefg']\nOk, this splits the string but we have an overlap specified as 5, but it looks like 3? (try an even number)\ntext3 = \"a b c d e f g h i j k l m n o p q r s t u v w x y z\"\nr_splitter.split_text(text3)\n\n['a b c d e f g h i j k l m', 'l m n o p q r s t u v w x', 'w x y z']\nc_splitter.split_text(text3)\n\n['a b c d e f g h i j k l m n o p q r s t u v w x y z']\nc_splitter = CharacterTextSplitter(\n    chunk_size=chunk_size,\n    chunk_overlap=chunk_overlap,\n    separator = ' '\n)\nc_splitter.split_text(text3)\n\n['a b c d e f g h i j k l m', 'l m n o p q r s t u v w x', 'w x y z']\nTry your own examples!"
  },
  {
    "objectID": "slides/02_document_splitting.html#recursive-splitting-details",
    "href": "slides/02_document_splitting.html#recursive-splitting-details",
    "title": "Document Splitting",
    "section": "Recursive splitting details",
    "text": "Recursive splitting details\nRecursiveCharacterTextSplitter is recommended for generic text.\n\nsome_text = \"\"\"When writing documents, writers will use document structure to group content. \\\nThis can convey to the reader, which idea's are related. For example, closely related ideas \\\nare in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n  \\\nParagraphs are often delimited with a carriage return or two carriage returns. \\\nCarriage returns are the \"backslash n\" you see embedded in this string. \\\nSentences have a period at the end, but also, have a space.\\\nand words are separated by space.\"\"\"\n\n\nlen(some_text)\n\n\nc_splitter = CharacterTextSplitter(\n    chunk_size=450,\n    chunk_overlap=0,\n    separator = ' '\n)\nr_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=450,\n    chunk_overlap=0, \n    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n)\n\n\nc_splitter.split_text(some_text)\n\n['When writing documents, writers will use document structure to group content. This can convey to the reader, which idea\\'s are related. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this string. Sentences have a period at the end, but also,',\n 'have a space.and words are separated by space.']\n\n\n\nr_splitter.split_text(some_text)\n\n[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.\",\n 'Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this string. Sentences have a period at the end, but also, have a space.and words are separated by space.']\n\n\nLet‚Äôs reduce the chunk size a bit and add a period to our separators:\n\nr_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=150,\n    chunk_overlap=0,\n    separators=[\"\\n\\n\", \"\\n\", \"\\. \", \" \", \"\"]\n)\nr_splitter.split_text(some_text)\n\n[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related\",\n '. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.',\n 'Paragraphs are often delimited with a carriage return or two carriage returns',\n '. Carriage returns are the \"backslash n\" you see embedded in this string',\n '. Sentences have a period at the end, but also, have a space.and words are separated by space.']\n\n\n\nr_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=150,\n    chunk_overlap=0,\n    separators=[\"\\n\\n\", \"\\n\", \"(?&lt;=\\. )\", \" \", \"\"]\n)\nr_splitter.split_text(some_text)\n\n[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related.\",\n 'For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.',\n 'Paragraphs are often delimited with a carriage return or two carriage returns.',\n 'Carriage returns are the \"backslash n\" you see embedded in this string.',\n 'Sentences have a period at the end, but also, have a space.and words are separated by space.']\n\n\n\nfrom langchain.document_loaders import PyPDFLoader\nloader = PyPDFLoader(\"docs/cs229_lectures/MachineLearning-Lecture01.pdf\")\npages = loader.load()\n\n\nfrom langchain.text_splitter import CharacterTextSplitter\ntext_splitter = CharacterTextSplitter(\n    separator=\"\\n\",\n    chunk_size=1000,\n    chunk_overlap=150,\n    length_function=len\n)\n\n\ndocs = text_splitter.split_documents(pages)\n\n\nlen(docs)\n\n77\n\n\n\nlen(pages)\n\n22\n\n\n\nfrom langchain.document_loaders import NotionDirectoryLoader\nloader = NotionDirectoryLoader(\"docs/Notion_DB\")\nnotion_db = loader.load()\n\n\ndocs = text_splitter.split_documents(notion_db)\n\n\nlen(notion_db)\n\n1\n\n\n\nlen(docs)\n\n2"
  },
  {
    "objectID": "slides/02_document_splitting.html#token-splitting",
    "href": "slides/02_document_splitting.html#token-splitting",
    "title": "Document Splitting",
    "section": "Token splitting",
    "text": "Token splitting\nWe can also split on token count explicity, if we want.\nThis can be useful because LLMs often have context windows designated in tokens.\nTokens are often ~4 characters.\n\nfrom langchain.text_splitter import TokenTextSplitter\n\n\ntext_splitter = TokenTextSplitter(chunk_size=1, chunk_overlap=0)\n\n\ntext1 = \"foo bar bazzyfoo\"\n\n\ntext_splitter.split_text(text1)\n\n['foo', ' bar', ' b', 'az', 'zy', 'foo']\n\n\n\ntext_splitter = TokenTextSplitter(chunk_size=10, chunk_overlap=0)\n\n\ndocs = text_splitter.split_documents(pages)\n\n\ndocs[0]\n\nDocument(page_content='MachineLearning-Lecture01  \\n', metadata={'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf', 'page': 0})\n\n\n\npages[0].metadata\n\n{'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf', 'page': 0}"
  },
  {
    "objectID": "slides/02_document_splitting.html#context-aware-splitting",
    "href": "slides/02_document_splitting.html#context-aware-splitting",
    "title": "Document Splitting",
    "section": "Context aware splitting",
    "text": "Context aware splitting\nChunking aims to keep text with common context together.\nA text splitting often uses sentences or other delimiters to keep related text together but many documents (such as Markdown) have structure (headers) that can be explicitly used in splitting.\nWe can use MarkdownHeaderTextSplitter to preserve header metadata in our chunks, as show below.\n\nfrom langchain.document_loaders import NotionDirectoryLoader\nfrom langchain.text_splitter import MarkdownHeaderTextSplitter\n\n\nmarkdown_document = \"\"\"# Title\\n\\n \\\n## Chapter 1\\n\\n \\\nHi this is Jim\\n\\n Hi this is Joe\\n\\n \\\n### Section \\n\\n \\\nHi this is Lance \\n\\n \n## Chapter 2\\n\\n \\\nHi this is Molly\"\"\"\n\n\n\nheaders_to_split_on = [\n    (\"#\", \"Header 1\"),\n    (\"##\", \"Header 2\"),\n    (\"###\", \"Header 3\"),\n]\n\n\nmarkdown_splitter = MarkdownHeaderTextSplitter(\n    headers_to_split_on=headers_to_split_on\n)\nmd_header_splits = markdown_splitter.split_text(markdown_document)\n\n\nmd_header_splits[0]\n\nDocument(page_content='Hi this is Jim  \\nHi this is Joe', metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1'})\n\n\n\nmd_header_splits[1]\n\nDocument(page_content='Hi this is Lance', metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1', 'Header 3': 'Section'})\n\n\nTry on a real Markdown file, like a Notion database.\n\nloader = NotionDirectoryLoader(\"docs/Notion_DB\")\ndocs = loader.load()\ntxt = ' '.join([d.page_content for d in docs])\n\n\nheaders_to_split_on = [\n    (\"#\", \"Header 1\"),\n    (\"##\", \"Header 2\"),\n]\nmarkdown_splitter = MarkdownHeaderTextSplitter(\n    headers_to_split_on=headers_to_split_on\n)\n\n\nmd_header_splits = markdown_splitter.split_text(txt)\n\n\nmd_header_splits[0]\n\nDocument(page_content='üëã Welcome to Notion!  \\nHere are the basics:  \\n- [ ]  Click anywhere and just start typing\\n- [ ]  Hit `/` to see all the types of content you can add - headers, videos, sub pages, etc.  \\n[Example sub page](https://www.notion.so/Example-sub-page-92f63253929d456bbf12cd696e21e045?pvs=21)  \\n- [ ]  Highlight any text, and use the menu that pops up to **style** *your* ~~writing~~ `however` [you](https://www.notion.so/product) like\\n- [ ]  See the `‚ãÆ‚ãÆ` to the left of this checkbox on hover? Click and drag to move this line\\n- [ ]  Click the `+ New Page` button at the bottom of your sidebar to add a new page\\n- [ ]  Click `Templates` in your sidebar to get started with pre-built pages\\n- This is a toggle block. Click the little triangle to see more useful tips!\\n- [Template Gallery](https://www.notion.so/181e961aeb5c4ee6915307c0dfd5156d?pvs=21): More templates built by the Notion community\\n- [Help & Support](https://www.notion.so/e040febf70a94950b8620e6f00005004?pvs=21): ****Guides and FAQs for everything in Notion\\n- Stay organized with your sidebar and nested pages:  \\n![Getting%20Started%2095e5ecbe48c44e408ef09fed850fbd40/infinitehierarchynodither.gif](Getting%20Started%2095e5ecbe48c44e408ef09fed850fbd40/infinitehierarchynodither.gif)  \\nSee it in action:  \\n[1 minute](https://youtu.be/TL_N2pmh9O0)  \\n1 minute  \\n[4 minutes](https://youtu.be/FXIrojSK3Jo)  \\n4 minutes  \\n[2 minutes](https://youtu.be/2Pwzff-uffU)  \\n2 minutes  \\n[2 minutes](https://youtu.be/O8qdvSxDYNY)  \\n2 minutes  \\nVisit our [YouTube channel](http://youtube.com/c/notion) to watch 50+ more tutorials  \\nüëâ**Have a question?** Click the `?` at the bottom right for more guides, or to send us a message.', metadata={'Header 1': 'Getting Started'})"
  },
  {
    "objectID": "slides/04_retrieval.html",
    "href": "slides/04_retrieval.html",
    "title": "Retrieval",
    "section": "",
    "text": "Retrieval is the centerpiece of our retrieval augmented generation (RAG) flow.\nLet‚Äôs get our vectorDB from before."
  },
  {
    "objectID": "slides/04_retrieval.html#vectorstore-retrieval",
    "href": "slides/04_retrieval.html#vectorstore-retrieval",
    "title": "Retrieval",
    "section": "Vectorstore retrieval",
    "text": "Vectorstore retrieval\n\nimport os\nimport openai\nimport sys\nsys.path.append('../..')\n\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv()) # read local .env file\n\nopenai.api_key  = os.environ['OPENAI_API_KEY']\n\n\n#!pip install lark\n\n\nSimilarity Search\n\nfrom langchain.vectorstores import Chroma\nfrom langchain.embeddings.openai import OpenAIEmbeddings\npersist_directory = 'docs/chroma/'\n\n\nembedding = OpenAIEmbeddings()\nvectordb = Chroma(\n    persist_directory=persist_directory,\n    embedding_function=embedding\n)\n\n\nprint(vectordb._collection.count())\n\n209\n\n\n\ntexts = [\n    \"\"\"The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).\"\"\",\n    \"\"\"A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.\"\"\",\n    \"\"\"A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.\"\"\",\n]\n\n\nsmalldb = Chroma.from_texts(texts, embedding=embedding)\n\n\nquestion = \"Tell me about all-white mushrooms with large fruiting bodies\"\n\n\nsmalldb.similarity_search(question, k=2)\n\n[Document(page_content='A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.', metadata={}),\n Document(page_content='The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).', metadata={})]\n\n\n\nsmalldb.max_marginal_relevance_search(question,k=2, fetch_k=3)\n\n[Document(page_content='A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.', metadata={}),\n Document(page_content='A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.', metadata={})]\n\n\n\n\nAddressing Diversity: Maximum marginal relevance\nLast class we introduced one problem: how to enforce diversity in the search results.\nMaximum marginal relevance strives to achieve both relevance to the query and diversity among the results.\n\nquestion = \"what did they say about matlab?\"\ndocs_ss = vectordb.similarity_search(question,k=3)\n\n\ndocs_ss[0].page_content[:100]\n\n'those homeworks will be done in either MATLA B or in Octave, which is sort of ‚Äî I \\nknow some people '\n\n\n\ndocs_ss[1].page_content[:100]\n\n'those homeworks will be done in either MATLA B or in Octave, which is sort of ‚Äî I \\nknow some people '\n\n\nNote the difference in results with MMR.\n\ndocs_mmr = vectordb.max_marginal_relevance_search(question,k=3)\n\n\ndocs_mmr[0].page_content[:100]\n\n'those homeworks will be done in either MATLA B or in Octave, which is sort of ‚Äî I \\nknow some people '\n\n\n\ndocs_mmr[1].page_content[:100]\n\n\"mathematical work, he feels like he's disc overing truth and beauty in the universe. And \\nhe says it\"\n\n\n\n\nAddressing Specificity: working with metadata\nIn last lecture, we showed that a question about the third lecture can include results from other lectures as well.\nTo address this, many vectorstores support operations on metadata.\nmetadata provides context for each embedded chunk.\n\nquestion = \"what did they say about regression in the third lecture?\"\n\n\ndocs = vectordb.similarity_search(\n    question,\n    k=3,\n    filter={\"source\":\"docs/cs229_lectures/MachineLearning-Lecture03.pdf\"}\n)\n\n\nfor d in docs:\n    print(d.metadata)\n\n{'source': 'docs/cs229_lectures/MachineLearning-Lecture03.pdf', 'page': 0}\n{'source': 'docs/cs229_lectures/MachineLearning-Lecture03.pdf', 'page': 14}\n{'source': 'docs/cs229_lectures/MachineLearning-Lecture03.pdf', 'page': 4}\n\n\n\n\nAddressing Specificity: working with metadata using self-query retriever\nBut we have an interesting challenge: we often want to infer the metadata from the query itself.\nTo address this, we can use SelfQueryRetriever, which uses an LLM to extract:\n\nThe query string to use for vector search\nA metadata filter to pass in as well\n\nMost vector databases support metadata filters, so this doesn‚Äôt require any new databases or indexes.\n\nfrom langchain.llms import OpenAI\nfrom langchain.retrievers.self_query.base import SelfQueryRetriever\nfrom langchain.chains.query_constructor.base import AttributeInfo\n\n\nmetadata_field_info = [\n    AttributeInfo(\n        name=\"source\",\n        description=\"The lecture the chunk is from, should be one of `docs/cs229_lectures/MachineLearning-Lecture01.pdf`, `docs/cs229_lectures/MachineLearning-Lecture02.pdf`, or `docs/cs229_lectures/MachineLearning-Lecture03.pdf`\",\n        type=\"string\",\n    ),\n    AttributeInfo(\n        name=\"page\",\n        description=\"The page from the lecture\",\n        type=\"integer\",\n    ),\n]\n\n\ndocument_content_description = \"Lecture notes\"\nllm = OpenAI(temperature=0)\nretriever = SelfQueryRetriever.from_llm(\n    llm,\n    vectordb,\n    document_content_description,\n    metadata_field_info,\n    verbose=True\n)\n\n\nquestion = \"what did they say about regression in the third lecture?\"\n\nYou will receive a warning about predict_and_parse being deprecated the first time you executing the next line. This can be safely ignored.\n\ndocs = retriever.get_relevant_documents(question)\n\n/Users/jankirenz/anaconda3/envs/langchain/lib/python3.11/site-packages/langchain/chains/llm.py:275: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n  warnings.warn(\n\n\nquery='regression' filter=Comparison(comparator=&lt;Comparator.EQ: 'eq'&gt;, attribute='source', value='docs/cs229_lectures/MachineLearning-Lecture03.pdf') limit=None\n\n\n\nfor d in docs:\n    print(d.metadata)\n\n{'source': 'docs/cs229_lectures/MachineLearning-Lecture03.pdf', 'page': 14}\n{'source': 'docs/cs229_lectures/MachineLearning-Lecture03.pdf', 'page': 0}\n{'source': 'docs/cs229_lectures/MachineLearning-Lecture03.pdf', 'page': 10}\n{'source': 'docs/cs229_lectures/MachineLearning-Lecture03.pdf', 'page': 10}\n\n\n\n\nAdditional tricks: compression\nAnother approach for improving the quality of retrieved docs is compression.\nInformation most relevant to a query may be buried in a document with a lot of irrelevant text.\nPassing that full document through your application can lead to more expensive LLM calls and poorer responses.\nContextual compression is meant to fix this.\n\nfrom langchain.retrievers import ContextualCompressionRetriever\nfrom langchain.retrievers.document_compressors import LLMChainExtractor\n\n\ndef pretty_print_docs(docs):\n    print(f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]))\n\n\n# Wrap our vectorstore\nllm = OpenAI(temperature=0)\ncompressor = LLMChainExtractor.from_llm(llm)\n\n\ncompression_retriever = ContextualCompressionRetriever(\n    base_compressor=compressor,\n    base_retriever=vectordb.as_retriever()\n)\n\n\nquestion = \"what did they say about matlab?\"\ncompressed_docs = compression_retriever.get_relevant_documents(question)\npretty_print_docs(compressed_docs)\n\nDocument 1:\n\n\"MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to plot data. And it's sort of an extremely easy to learn tool to use for implementing a lot of learning algorithms.\"\n----------------------------------------------------------------------------------------------------\nDocument 2:\n\n\"MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to plot data. And it's sort of an extremely easy to learn tool to use for implementing a lot of learning algorithms.\"\n----------------------------------------------------------------------------------------------------\nDocument 3:\n\n\"And the student said, \"Oh, it was the MATLAB.\" So for those of you that don't know MATLAB yet, I hope you do learn it. It's not hard, and we'll actually have a short MATLAB tutorial in one of the discussion sections for those of you that don't know it.\"\n----------------------------------------------------------------------------------------------------\nDocument 4:\n\n\"And the student said, \"Oh, it was the MATLAB.\" So for those of you that don't know MATLAB yet, I hope you do learn it. It's not hard, and we'll actually have a short MATLAB tutorial in one of the discussion sections for those of you that don't know it.\""
  },
  {
    "objectID": "slides/04_retrieval.html#combining-various-techniques",
    "href": "slides/04_retrieval.html#combining-various-techniques",
    "title": "Retrieval",
    "section": "Combining various techniques",
    "text": "Combining various techniques\n\ncompression_retriever = ContextualCompressionRetriever(\n    base_compressor=compressor,\n    base_retriever=vectordb.as_retriever(search_type = \"mmr\")\n)\n\n\nquestion = \"what did they say about matlab?\"\ncompressed_docs = compression_retriever.get_relevant_documents(question)\npretty_print_docs(compressed_docs)\n\nDocument 1:\n\n\"MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to plot data. And it's sort of an extremely easy to learn tool to use for implementing a lot of learning algorithms.\"\n----------------------------------------------------------------------------------------------------\nDocument 2:\n\n\"And the student said, \"Oh, it was the MATLAB.\" So for those of you that don't know MATLAB yet, I hope you do learn it. It's not hard, and we'll actually have a short MATLAB tutorial in one of the discussion sections for those of you that don't know it.\""
  },
  {
    "objectID": "slides/04_retrieval.html#other-types-of-retrieval",
    "href": "slides/04_retrieval.html#other-types-of-retrieval",
    "title": "Retrieval",
    "section": "Other types of retrieval",
    "text": "Other types of retrieval\nIt‚Äôs worth noting that vectordb as not the only kind of tool to retrieve documents.\nThe LangChain retriever abstraction includes other ways to retrieve documents, such as TF-IDF or SVM.\n\nfrom langchain.retrievers import SVMRetriever\nfrom langchain.retrievers import TFIDFRetriever\nfrom langchain.document_loaders import PyPDFLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\n\n\n# Load PDF\nloader = PyPDFLoader(\"docs/cs229_lectures/MachineLearning-Lecture01.pdf\")\npages = loader.load()\nall_page_text=[p.page_content for p in pages]\njoined_page_text=\" \".join(all_page_text)\n\n# Split\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size = 1500,chunk_overlap = 150)\nsplits = text_splitter.split_text(joined_page_text)\n\n\n# Retrieve\nsvm_retriever = SVMRetriever.from_texts(splits,embedding)\ntfidf_retriever = TFIDFRetriever.from_texts(splits)\n\n\nquestion = \"What are major topics for this class?\"\ndocs_svm=svm_retriever.get_relevant_documents(question)\ndocs_svm[0]\n\n/Users/jankirenz/anaconda3/envs/langchain/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n  warnings.warn(\n\n\nDocument(page_content=\"let me just check what questions you have righ t now. So if there are no questions, I'll just \\nclose with two reminders, which are after class today or as you start to talk with other \\npeople in this class, I just encourage you again to start to form project partners, to try to \\nfind project partners to do your project with. And also, this is a good time to start forming \\nstudy groups, so either talk to your friends  or post in the newsgroup, but we just \\nencourage you to try to star t to do both of those today, okay? Form study groups, and try \\nto find two other project partners.  \\nSo thank you. I'm looking forward to teaching this class, and I'll see you in a couple of \\ndays.   [End of Audio]  \\nDuration: 69 minutes\", metadata={})\n\n\n\nquestion = \"what did they say about matlab?\"\ndocs_tfidf=tfidf_retriever.get_relevant_documents(question)\ndocs_tfidf[0]\n\nDocument(page_content=\"Saxena and Min Sun here did, wh ich is given an image like this, right? This is actually a \\npicture taken of the Stanford campus. You can apply that sort of cl ustering algorithm and \\ngroup the picture into regions. Let me actually blow that up so that you can see it more \\nclearly. Okay. So in the middle, you see the lines sort of groupi ng the image together, \\ngrouping the image into [inaudible] regions.  \\nAnd what Ashutosh and Min did was they then  applied the learning algorithm to say can \\nwe take this clustering and us e it to build a 3D model of the world? And so using the \\nclustering, they then had a lear ning algorithm try to learn what the 3D structure of the \\nworld looks like so that they could come up with a 3D model that you can sort of fly \\nthrough, okay? Although many people used to th ink it's not possible to take a single \\nimage and build a 3D model, but using a lear ning algorithm and that sort of clustering \\nalgorithm is the first step. They were able to.  \\nI'll just show you one more example. I like this  because it's a picture of Stanford with our \\nbeautiful Stanford campus. So again, taking th e same sort of clustering algorithms, taking \\nthe same sort of unsupervised learning algor ithm, you can group the pixels into different \\nregions. And using that as a pre-processing step, they eventually built this sort of 3D model of Stanford campus in a single picture.  You can sort of walk  into the ceiling, look\", metadata={})"
  },
  {
    "objectID": "slides/06_chat.html",
    "href": "slides/06_chat.html",
    "title": "Chat",
    "section": "",
    "text": "Recall the overall workflow for retrieval augmented generation (RAG):\nWe discussed Document Loading and Splitting as well as Storage and Retrieval.\nWe then showed how Retrieval can be used for output generation in Q+A using RetrievalQA chain.\nimport os\nimport openai\nimport sys\nsys.path.append('../..')\n\nimport panel as pn  # GUI\npn.extension()\n\nfrom dotenv import load_dotenv, find_dotenv\n_ = load_dotenv(find_dotenv()) # read local .env file\n\nopenai.api_key  = os.environ['OPENAI_API_KEY']\nThe code below was added to assign the openai LLM version filmed until it is deprecated, currently in Sept 2023. LLM responses can often vary, but the responses may be significantly different when using a different model version.\nimport datetime\ncurrent_date = datetime.datetime.now().date()\nif current_date &lt; datetime.date(2023, 9, 2):\n    llm_name = \"gpt-3.5-turbo-0301\"\nelse:\n    llm_name = \"gpt-3.5-turbo\"\nprint(llm_name)\n\ngpt-3.5-turbo-0301\nIf you wish to experiment on LangChain plus platform:\n# import os\n# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n# os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.langchain.plus\"\n# os.environ[\"LANGCHAIN_API_KEY\"] = \"...\"\nfrom langchain.vectorstores import Chroma\nfrom langchain.embeddings.openai import OpenAIEmbeddings\npersist_directory = 'docs/chroma/'\nembedding = OpenAIEmbeddings()\nvectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)\nquestion = \"What are major topics for this class?\"\ndocs = vectordb.similarity_search(question,k=3)\nlen(docs)\n\n3\nfrom langchain.chat_models import ChatOpenAI\nllm = ChatOpenAI(model_name=llm_name, temperature=0)\nllm.predict(\"Hello world!\")\n\n'Hello there! How can I assist you today?'\n# Build prompt\nfrom langchain.prompts import PromptTemplate\ntemplate = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer. \n{context}\nQuestion: {question}\nHelpful Answer:\"\"\"\nQA_CHAIN_PROMPT = PromptTemplate(input_variables=[\"context\", \"question\"],template=template,)\n\n# Run chain\nfrom langchain.chains import RetrievalQA\nquestion = \"Is probability a class topic?\"\nqa_chain = RetrievalQA.from_chain_type(llm,\n                                       retriever=vectordb.as_retriever(),\n                                       return_source_documents=True,\n                                       chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT})\n\n\nresult = qa_chain({\"query\": question})\nresult[\"result\"]\n\n'Yes, probability is assumed to be a prerequisite for this class. The instructor assumes familiarity with basic probability and statistics, and will go over some of the prerequisites in the discussion sections as a refresher course. Thanks for asking!'"
  },
  {
    "objectID": "slides/06_chat.html#acknowledgments",
    "href": "slides/06_chat.html#acknowledgments",
    "title": "Chat",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nPanel based chatbot inspired by Sophia Yang, github"
  }
]